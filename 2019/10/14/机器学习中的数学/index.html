<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/Ppaddington.github.io/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/Ppaddington.github.io/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/Ppaddington.github.io/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/Ppaddington.github.io/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/Ppaddington.github.io/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/Ppaddington.github.io/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/Ppaddington.github.io/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="机器学习,">










<meta name="description" content="数学在机器学习中的应用模型建立与选择：对工程问题进行抽象和量化&amp;emsp;&amp;emsp;• 涉及数学知识：综合运用微积分，线性代数，概率统计以及组合数学的知识。例如：&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;o 各类深度模型中的网络结构与损失函数&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;o 支持向量机中的向量空间与度量 模型训练：&amp;emsp;&amp;emsp;• 优化算法：高效稳定的对各类损失">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习中的数学">
<meta property="og:url" content="https://ppaddington.github.io/Ppaddington.github.io/2019/10/14/机器学习中的数学/index.html">
<meta property="og:site_name" content="lalala">
<meta property="og:description" content="数学在机器学习中的应用模型建立与选择：对工程问题进行抽象和量化&amp;emsp;&amp;emsp;• 涉及数学知识：综合运用微积分，线性代数，概率统计以及组合数学的知识。例如：&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;o 各类深度模型中的网络结构与损失函数&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;o 支持向量机中的向量空间与度量 模型训练：&amp;emsp;&amp;emsp;• 优化算法：高效稳定的对各类损失">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://ppaddington.github.io/Ppaddington.github.io/2019/10/14/机器学习中的数学/2.png">
<meta property="og:image" content="https://ppaddington.github.io/Ppaddington.github.io/2019/10/14/机器学习中的数学/3.png">
<meta property="og:image" content="https://ppaddington.github.io/Ppaddington.github.io/2019/10/14/机器学习中的数学/琴生不等式证明.png">
<meta property="og:image" content="https://ppaddington.github.io/Ppaddington.github.io/2019/10/14/机器学习中的数学/局部极值.png">
<meta property="og:updated_time" content="2019-10-23T04:31:32.472Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习中的数学">
<meta name="twitter:description" content="数学在机器学习中的应用模型建立与选择：对工程问题进行抽象和量化&amp;emsp;&amp;emsp;• 涉及数学知识：综合运用微积分，线性代数，概率统计以及组合数学的知识。例如：&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;o 各类深度模型中的网络结构与损失函数&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;o 支持向量机中的向量空间与度量 模型训练：&amp;emsp;&amp;emsp;• 优化算法：高效稳定的对各类损失">
<meta name="twitter:image" content="https://ppaddington.github.io/Ppaddington.github.io/2019/10/14/机器学习中的数学/2.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/Ppaddington.github.io/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://ppaddington.github.io/Ppaddington.github.io/2019/10/14/机器学习中的数学/">





  <title>机器学习中的数学 | lalala</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/Ppaddington.github.io/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">lalala</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">帅帅的昊:-)</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/Ppaddington.github.io/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/Ppaddington.github.io/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/Ppaddington.github.io/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/Ppaddington.github.io/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ppaddington.github.io/Ppaddington.github.io/Ppaddington.github.io/2019/10/14/机器学习中的数学/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="lalala">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/Ppaddington.github.io/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="lalala">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">机器学习中的数学</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-14T21:03:22+08:00">
                2019-10-14
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-10-23T12:31:32+08:00">
                2019-10-23
              </time>
            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  3.8k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  15
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="数学在机器学习中的应用"><a href="#数学在机器学习中的应用" class="headerlink" title="数学在机器学习中的应用"></a>数学在机器学习中的应用</h1><h2 id="模型建立与选择：对工程问题进行抽象和量化"><a href="#模型建立与选择：对工程问题进行抽象和量化" class="headerlink" title="模型建立与选择：对工程问题进行抽象和量化"></a>模型建立与选择：对工程问题进行抽象和量化</h2><p>&emsp;&emsp;• 涉及数学知识：综合运用微积分，线性代数，概率统计以及组合数学的知识。例如：<br>&emsp;&emsp;&emsp;&emsp;o 各类深度模型中的网络结构与损失函数<br>&emsp;&emsp;&emsp;&emsp;o 支持向量机中的向量空间与度量</p>
<h2 id="模型训练："><a href="#模型训练：" class="headerlink" title="模型训练："></a>模型训练：</h2><p>&emsp;&emsp;• 优化算法：高效稳定的对各类损失函数求极值<br>&emsp;&emsp;• 涉及数学知识：微积分以及优化理论</p>
<a id="more"></a>
<h1 id="微积分"><a href="#微积分" class="headerlink" title="微积分"></a>微积分</h1><h2 id="微积分核心思想：函数逼近"><a href="#微积分核心思想：函数逼近" class="headerlink" title="微积分核心思想：函数逼近"></a>微积分核心思想：函数逼近</h2><p>&emsp;&emsp;微分学的核心思想是用熟悉且简单的函数对复杂函数进行局部逼近。常用作逼近的简单函数包括：<br>&emsp;&emsp;• 线性函数：函数的一阶导数<br>&emsp;&emsp;• 多项式函数：泰勒级数</p>
<h2 id="极限"><a href="#极限" class="headerlink" title="极限"></a>极限</h2><p>&emsp;&emsp;极限的表述方式：<br>&emsp;&emsp;• 自然语言：当x趋近于α时，$ f(x) $的极限是L。<br>&emsp;&emsp;• 数学符号：$\lim\limits_{x \rightarrow α} f(x) = L$。<br>&emsp;&emsp;• 数学定义：对于任意的 $\epsilon$&gt;0，存在一个$\Delta$&gt;0，使得对于任何的x∈(a-$\Delta$, a+$\Delta$)，都有$ |f(x) - L| &lt; \epsilon $。<br>&emsp;&emsp;无穷小阶数：趋近于0的速度越快的无穷小，其阶数越高。比 $ x^n, x\rightarrow0 $ 趋近于0速度还快的无穷小记作 $ o(x^n) $<br>&emsp;&emsp;两夹边定理：如果 $ f(x) &lt; g(x) &lt; h(x) $，而且这三个函数都在a点处有极限，那么</p>
<script type="math/tex; mode=display">\lim\limits_{x \rightarrow α} f(x) ≤ \lim\limits_{x \rightarrow α} g(x) ≤ \lim\limits_{x \rightarrow α} h(x)</script><h2 id="导数"><a href="#导数" class="headerlink" title="导数"></a>导数</h2><p>&emsp;&emsp;微积分核心思想是逼近，一阶导数：$ f’(x) = \lim\limits_{\Delta \rightarrow 0} \frac{f(x+\Delta)-f(x)}{\Delta} $<br>&emsp;&emsp;• 几何意义：用直线逼近曲线<br>&emsp;&emsp;• 用线性函数逼近复杂函数</p>
<h2 id="从线性逼近到多项式逼近：泰勒级数"><a href="#从线性逼近到多项式逼近：泰勒级数" class="headerlink" title="从线性逼近到多项式逼近：泰勒级数"></a>从线性逼近到多项式逼近：泰勒级数</h2><p>&emsp;&emsp;Talor级数就是利用n阶导数来对函数进行高阶逼近。<br>&emsp;&emsp;如果一个函数$ f(x) $是n阶可微函数，那么：</p>
<script type="math/tex; mode=display">f(x_0+\Delta) = f(x_0) + f'(x_0)\Delta + \frac{f^{(2)}(x_0)}{2}\Delta^2 + … + \frac{f^{(n)}(x_0)}{n!}\Delta^n + o(\Delta^n)</script><p>&emsp;&emsp;当n=2时，Talor级数就成为一个二次逼近，对于2阶可微函数 $f(x)$：</p>
<script type="math/tex; mode=display">f(x_0+\Delta) = f(x_0) + f'(x_0)\Delta + \frac{f^{(2)}(x_0)}{2}\Delta^2 + o(\Delta^n)</script><p>&emsp;&emsp;这构成了牛顿法的基础。</p>
<h2 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h2><p>&emsp;&emsp;梯度下降是一个用来求函数最小值的算法，其思想是：开始时我们随机选择一个参数的组合 $ (𝜃_0, 𝜃_1, ……, 𝜃_𝑛) $ ，计算代价函数，然后我们寻找下一个能让代价函数值下降最多的参数组合。我们持续这么做直到到到一个局部最小值（local minimum），因为我们并没有尝试完所有的参数组合，所以不能确定我们得到的局部最小值是否便是全局最小值（global minimum），选择不同的初始参数组合，可能会找到不同的局部最小值。<br>&emsp;&emsp;想象一下你正站立在山坡的一点上，在梯度下降算法中，我们要做的就是旋转 360 度，看看我们的周围，然后你按照自己的判断在某个方向上迈出一步尽快下山；从这个新的点，你环顾四周，并决定从什么方向将会最快下山，然后又迈进了一小步，并依此类推，直到你接近局部最低点的位置。<br>&emsp;&emsp;批量梯度下降（batch gradient descent）算法的公式为：<br>&emsp;&emsp;𝑅𝑒𝑝𝑒𝑎𝑡 𝑢𝑛𝑡𝑖𝑙 𝑐𝑜𝑛𝑣𝑒𝑟𝑔𝑒𝑛𝑐𝑒{<br>&emsp;&emsp;&emsp;&emsp;$ 𝜃_𝑗 := 𝜃_𝑗 − 𝛼 \frac{\partial} {\partial θ_j} J(𝜃_0, 𝜃_1) &emsp;&emsp; (for j=0 and j=1) $<br>&emsp;&emsp;}<br>&emsp;&emsp;其中𝑎是学习率（learning rate），它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大，在批量梯度下降中，我们每一次都同时让所有的参数减去学习速率乘以代价函数的导数。<br>&emsp;&emsp;如果𝑎太小了，即我的学习速率太小，结果就是只能一点点地挪动，这样就需要很多步才能到达最低点。<br>&emsp;&emsp;如果𝑎太大，那么梯度下降法可能会越过最低点，甚至可能无法收敛，下一次迭代又移动了一大步，越过一次，又越过一次，一次次越过最低点，直到你发现实际上离最低点越来越远，所以，如果𝑎太大，它会导致无法收敛，甚至发散。<br><img src="/Ppaddington.github.io/2019/10/14/机器学习中的数学/2.png"></p>
<h2 id="梯度下降的线性回归"><a href="#梯度下降的线性回归" class="headerlink" title="梯度下降的线性回归"></a>梯度下降的线性回归</h2><p>&emsp;&emsp;梯度下降是很常用的算法，它不仅被用在线性回归上和线性回归模型、平方误差代价函数。我们将梯度下降和代价函数结合，并将其应用于具体的拟合直线的线性回归算法里。<br>&emsp;&emsp;梯度下降算法和线性回归算法如图：<br><img src="/Ppaddington.github.io/2019/10/14/机器学习中的数学/3.png"></p>
<p>&emsp;&emsp;对我们之前的线性回归问题运用梯度下降法，关键在于求出代价函数的导数，即：</p>
<script type="math/tex; mode=display">
\frac{\partial} {\partial θ_j} J(𝜃_0, 𝜃_1) = \frac{\partial} {\partial θ_j} \frac{1}{2m} \sum_{i=1}^m (ℎ_𝜃(x^{(𝑖)}) − y^{(𝑖)})^2</script><p>&emsp;&emsp;j = 0 时: $ \frac{\partial} {\partial θ_j} J(𝜃_0, 𝜃_1) = \frac{1}{m} \sum_{i=1}^m (ℎ_𝜃(x^{(𝑖)}) − y^{(𝑖)}) $<br>&emsp;&emsp;j = 1 时: $ \frac{\partial} {\partial θ_j} J(𝜃_0, 𝜃_1) = \frac{1}{m} \sum_{i=1}^m ((ℎ_𝜃(x^{(𝑖)}) − y^{(𝑖)}))x^{(𝑖)} $<br>&emsp;&emsp;则算法改写成：<br>&emsp;&emsp;Repeat {<br>&emsp;&emsp;&emsp;&emsp;$ 𝜃_0 := 𝜃_0 - 𝛼 \frac{1}{m} \sum_{i=1}^m (ℎ_𝜃(x^{(𝑖)}) − y^{(𝑖)}) $<br>&emsp;&emsp;&emsp;&emsp;$ 𝜃_1 := 𝜃_1 - 𝛼 \frac{1}{m} \sum_{i=1}^m ((ℎ_𝜃(x^{(𝑖)}) − y^{(𝑖)}))x^{(𝑖)} $<br>&emsp;&emsp;}</p>
<p>&emsp;&emsp;我们刚刚使用的算法，有时也称为”批量梯度下降”。”批量梯度下降”，指的是在梯度下降的每一步中，我们都用到了所有的训练样本，在梯度下降中，在计算微分求导项时，我们需要进行求和运算，所以，在每一个单独的梯度下降中，我们最终都要计算这样一个东西，这个项需要对所有𝑚个训练样本求和。因此，批量梯度下降法这个名字说明了我们需要考虑所有这一”批”训练样本，而事实上，有时也有其他类型的梯度下降法，不是这种”批量”型的，不考虑整个的训练集，而是每次只关注训练集中的一些小的子集。</p>
<h2 id="多变量梯度下降"><a href="#多变量梯度下降" class="headerlink" title="多变量梯度下降"></a>多变量梯度下降</h2><p>&emsp;&emsp;与单变量线性回归类似，在多变量线性回归中，我们也构建一个代价函数，则这个代价函数是所有建模误差的平方和，即：</p>
<script type="math/tex; mode=display">
J(θ_0,θ_1,...,θ_n) =  \frac{1}{2m} \sum_{i=1}^m (ℎ_𝜃(x^{(𝑖)}) − y^{(𝑖)})^2</script><p>&emsp;&emsp;其中，$ ℎ_𝜃(𝑥) = 𝜃^𝑇𝑋 = 𝜃_0 + 𝜃_1𝑥_1 + 𝜃_2𝑥_2+. . . +𝜃_𝑛𝑥_n $</p>
<p>&emsp;&emsp;我们的目标和单变量线性回归问题中一样，是要找出使得代价函数最小的一系列参数。多变量线性回归的批量梯度下降算法为：<br>&emsp;&emsp;Repeat {<br>&emsp;&emsp;&emsp;&emsp;$ 𝜃_j := 𝜃_j - 𝛼 \frac{\partial} {\partial θ_j} J(θ_0,θ_1,…,θ_n) $<br>&emsp;&emsp;}<br>&emsp;&emsp;即：<br>&emsp;&emsp;Repeat {<br>&emsp;&emsp;&emsp;&emsp;$ 𝜃_j := 𝜃_j - 𝛼 \frac{\partial} {\partial θ_j} \frac{1}{2m} \sum_{i=1}^m (ℎ_𝜃(x^{(𝑖)}) − y^{(𝑖)})^2 $<br>&emsp;&emsp;}<br>&emsp;&emsp;求导数后得到：<br>&emsp;&emsp;Repeat {<br>&emsp;&emsp;&emsp;&emsp;$ 𝜃_j := 𝜃_j - 𝛼 \frac{1}{m} \sum_{i=1}^m (ℎ_𝜃(x^{(𝑖)}) − y^{(𝑖)})x_j^{(𝑖)} $<br>&emsp;&emsp;}</p>
<h1 id="概率论"><a href="#概率论" class="headerlink" title="概率论"></a>概率论</h1><h2 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h2><p>&emsp;&emsp;假设抛10次硬币，实验的结果有6次是“花”。<br>&emsp;&emsp;所谓最大似然估计，利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值。在这个例子中是假设硬币的参数，然后计算实验结果的概率是多少，概率越大的，那么这个假设的参数就越可能是真的。</p>
<h1 id="凸优化"><a href="#凸优化" class="headerlink" title="凸优化"></a>凸优化</h1><h2 id="优化问题简介"><a href="#优化问题简介" class="headerlink" title="优化问题简介"></a>优化问题简介</h2><p>&emsp;&emsp;优化问题的一般形式<br>&emsp;&emsp;&emsp;&emsp;最小化：$ f_0(x) $<br>&emsp;&emsp;&emsp;&emsp;条件：$ f_i(x) ≤ b_i, i=1,…,m. $<br>&emsp;&emsp;其中，$ f_0(x)为目标函数，条件中的不等式为约束条件。$</p>
<h2 id="凸集合与凸函数"><a href="#凸集合与凸函数" class="headerlink" title="凸集合与凸函数"></a>凸集合与凸函数</h2><h4 id="凸集合"><a href="#凸集合" class="headerlink" title="凸集合"></a>凸集合</h4><p>&emsp;&emsp;如果一个集合$\Omega$中任何两个点之间的线段上的任何一个点还属于$\Omega$，那么$\Omega$就是一个凸集合，例如：</p>
<script type="math/tex; mode=display">\lambda x_1 + (1-\lambda)x_2 \in \Omega, \forall x_1,x_2 \in \Omega, \lambda \in (0,1)</script><h4 id="凸函数"><a href="#凸函数" class="headerlink" title="凸函数"></a>凸函数</h4><p>&emsp;&emsp;如果一个函数 $f$ 定义域 $\Omega$ 是凸集，而且对于任何两点，以及两点之间线段上任意一个点都有：</p>
<script type="math/tex; mode=display">f(\lambda x_1 + (1-\lambda)x_2) \leq \lambda f(x_1) + (1-\lambda)f(x_2) \forall x_1,x_2 \in \Omega, \lambda \in (0,1)</script><h4 id="上境图"><a href="#上境图" class="headerlink" title="上境图"></a>上境图</h4><p>&emsp;&emsp;假设 $f$ 是一个定义在 $\Omega$ 上的函数，区域 $\lbrace (x,y):y≥f(x), \forall x \in \Omega \rbrace$ 就是 $f$ 的上镜图。上镜图就是函数图像上方的部分区域。<br>&emsp;&emsp;一个函数是凸函数当且仅当 $f$ 的上镜图是凸集合。</p>
<h4 id="凸组合"><a href="#凸组合" class="headerlink" title="凸组合"></a>凸组合</h4><p>&emsp;&emsp;对于任何n个点 $\lbrace x_i \rbrace_{i=1}^n$，以及权重系数$\lbrace w_i \rbrace_{i=1}^n$。若权重系数非负并且 $\sum_{i=1}^n w_i = 1$，则线性组合 $ S = \sum_{i=1}^n w_i x_i $ 为一个凸组合。<br>&emsp;&emsp;凸组合的物理意义可以理解成n个重心为 $ w_i $ 的点的重心。</p>
<h4 id="集合的凸包"><a href="#集合的凸包" class="headerlink" title="集合的凸包"></a>集合的凸包</h4><p>&emsp;&emsp;n个点 $\lbrace x_i \rbrace_{i=1}^n$ 的全部凸组合就构成 $\lbrace x_i \rbrace_{i=1}^n$ 的凸包。</p>
<h4 id="函数的凸闭包"><a href="#函数的凸闭包" class="headerlink" title="函数的凸闭包"></a>函数的凸闭包</h4><p>&emsp;&emsp;如果 $C$ 是函数 $f$ 的上镜图，$\overline{C}$ 是 $C$ 的凸包，那么以 $\overline{C}$ 为上镜图的函数称为 $f$ 的凸闭包。</p>
<h4 id="凸集合的性质"><a href="#凸集合的性质" class="headerlink" title="凸集合的性质"></a>凸集合的性质</h4><p>&emsp;&emsp;假设 $\Omega$ 是一个凸集合，那么 $\Omega$ 任何子集的凸包仍包含与 $\Omega$ 。</p>
<h4 id="凸函数的性质"><a href="#凸函数的性质" class="headerlink" title="凸函数的性质"></a>凸函数的性质</h4><p>&emsp;&emsp;琴生不等式<br>&emsp;&emsp;如果 $ f:\Omega \rightarrow R $ 是一个凸函数，则对于任何 $ \lbrace x_i \in \Omega \rbrace_{i=1}^n $，以及凸组合 $\sum_{i=1}^n w_i x_i $ 都有</p>
<script type="math/tex; mode=display">\sum_{i=1}^n w_i f(x_i) ＞ f(\sum_{i=1}^n w_i x_i)</script><p>&emsp;&emsp;证明：<br><img src="/Ppaddington.github.io/2019/10/14/机器学习中的数学/琴生不等式证明.png"><br>&emsp;&emsp;凸函数的重要性质：局部极值一定是全局极值。<br><img src="/Ppaddington.github.io/2019/10/14/机器学习中的数学/局部极值.png"></p>
<h2 id="凸优化问题"><a href="#凸优化问题" class="headerlink" title="凸优化问题"></a>凸优化问题</h2><p>&emsp;&emsp;凸优化问题的一般形式<br>&emsp;&emsp;&emsp;&emsp;最小化：$ f_0(x) $<br>&emsp;&emsp;&emsp;&emsp;条件：$ f_i(x) ≤ b_i, i=1,…,m. $<br>&emsp;&emsp;其中，$ f_0(x)为目标函数，条件中的不等式为约束条件。$<br>&emsp;&emsp;• 凸优化问题的条件：$ f_0,f_1,…,f_m $ 都是凸函数。<br>&emsp;&emsp;• 凸优化问题的特点：局部最优等于全局最优。</p>
<p>&emsp;&emsp;凸优化问题的应用<br>&emsp;&emsp;• 凸优化问题逼近非凸优化问题，寻找非凸问题的初始点<br>&emsp;&emsp;• 利用对偶问题的凸性给原问题提供下界估计<br>&emsp;&emsp;• 凸优化问题可以给非凸问题带来一些启发</p>
<h2 id="优化问题的对偶性"><a href="#优化问题的对偶性" class="headerlink" title="优化问题的对偶性"></a>优化问题的对偶性</h2><h4 id="优化问题"><a href="#优化问题" class="headerlink" title="优化问题"></a>优化问题</h4><p>&emsp;&emsp;最小化：$ f_0(x) $<br>&emsp;&emsp;不等式条件：$ f_i(x) ≤ b_i, i=1,…,m. $<br>&emsp;&emsp;等式条件：$ h_i(x) = 0, i=1,…,p. $<br>&emsp;&emsp;定义域：$ D = \bigcap_{i=0}^m dom f_i \bigcap_{i=0}^m dom h_i $<br>&emsp;&emsp;定义域D指的是使得所有函数 $f_i,h_i$ 有定义的区域，而可行域指的是定义域中满足不等式条件与等式条件的那些点。我们把优化问题称为原问题，优化点记为 $x^*$，最优值记为 $p^*$。</p>
<h4 id="优化问题的对偶问题"><a href="#优化问题的对偶问题" class="headerlink" title="优化问题的对偶问题"></a>优化问题的对偶问题</h4><p>&emsp;&emsp;拉格朗日量：$ L(x,\lambda,v) = f_0(x) + \sum_{i=1}^m \lambda_i f_i(x) +\sum_{i=1}^p v_i h_i(x) $，$ \lambda_i v_i $ 称为拉格朗日乘子，限定 $ \lambda_i ≥ 0 $。<br>&emsp;&emsp;根据拉格朗日函数定义拉格朗日对偶函数:</p>
<script type="math/tex; mode=display">g(\lambda,v) = min L(x,\lambda,v) = minf_0(x) + \sum_{i=1}^m \lambda_i f_i(x) +\sum_{i=1}^p v_i h_i(x)</script><p>&emsp;&emsp;对偶函数为原问题提供下界：$ g(\lambda,v) ≤ p^*(p^*为原问题最优值) $<br>&emsp;&emsp;证明：对任意一个 $ x \in D $ 如果 $ x $ 在可行域中，那么</p>
<script type="math/tex; mode=display">g(\lambda,v) ≤ f_0(x) + \sum_{i=1}^m \lambda_i f_i(x) +\sum_{i=1}^p v_i h_i(x) = f_0(x) + \sum_{i=1}^m \lambda_i f_i(x) ≤ f_0(x)</script><p>&emsp;&emsp;关于拉格朗日对偶性还可参考<a href="https://zhuanlan.zhihu.com/p/38182879" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/38182879</a>。<br>&emsp;&emsp;根据对偶函数，定义对偶问题的一般形式：<br>&emsp;&emsp;最大化：$ g(\lambda,v) $<br>&emsp;&emsp;不等式条件：$ \lambda ≥ 0,i=1,…,m $<br>&emsp;&emsp;我们把对偶问题的最大值点记为 $(\lambda^*,v^*)$，相应的最大值记为 $d^*$。<br>&emsp;&emsp;在对偶可行域中，$ d^* = max min L(x,\lambda,v) ≤ min max L(x,\lambda,v) =  p^* $。<br>&emsp;&emsp;这个性质便叫做弱对偶性（weak duality），对于所有优化问题都成立，即使原始问题非凸。<br>&emsp;&emsp;与弱对偶性相对应的有一个强对偶性（strong duality） ，强对偶即满足：$ d^* =  p^* $。<br>&emsp;&emsp;强对偶是一个非常好的性质，因为在强对偶成立的情况下，可以通过求解对偶问题来得到原始问题的解，在 SVM 中就是这样做的。当然并不是所有的对偶问题都满足强对偶性 ，在 SVM 中是直接假定了强对偶性的成立，其实只要满足一些条件，强对偶性是成立的，比如说Slater条件与KKT条件。</p>
<h6 id="Slater-条件"><a href="#Slater-条件" class="headerlink" title="Slater 条件"></a>Slater 条件</h6><p>&emsp;&emsp;对于一个凸优化问题：<br>&emsp;&emsp;最小化：$ f_0(x) $<br>&emsp;&emsp;不等式条件：$ f_i(x) ≤ b_i, i=1,…,m. $<br>&emsp;&emsp;等式条件：$ h_i(x) = 0, i=1,…,p. $<br>&emsp;&emsp;如果存在一个可行域中的点 $ x $ 使得 $ f_i(x)&lt;0,i=1,…,m $，那么这个凸优化问题就满足强对偶条件。<br>&emsp;&emsp;满足强对偶性的例子：线性规划、最小二乘、最大熵问题。这种情况下我们如果发现对偶问题比原问题更容易解决，那么就可以使用对偶性来解出 $ d^* =  p^* $。</p>
<h6 id="KKT-条件"><a href="#KKT-条件" class="headerlink" title="KKT 条件"></a>KKT 条件</h6><p>&emsp;&emsp;如果强对偶性满足的话，这些最优化点应该满足何种条件.我们假定所有的函数都是可微函数.<br>&emsp;&emsp;如果 $ x^*,(\lambda^*,v^*) $ 分别是原问题与对偶问题的最优解，那么首先这些点应该满足可行域条件:<br>&emsp;&emsp;• $ f_i(x^*) ≤ 0 $<br>&emsp;&emsp;• $ h_i(x^*) = 0 $<br>&emsp;&emsp;• $ \lambda^* ≥ 0 $<br>&emsp;&emsp;而且我们知道<br>&emsp;&emsp;$ d^* = g(\lambda^*,v^*) ≤ f_0(x^*) + \sum_{i=1}^m \lambda_i^* f_i(x^*) +\sum_{i=1}^p v_i^* h_i(x^*) = f_0(x^*) + \sum_{i=1}^m \lambda_i^* f_i(x^*) ≤ f_0(x^*) = p^* $，于是$ d^* =  p^* $意味着上述不等式全是等式。<br>&emsp;&emsp;所以我们有$ \sum_{i=1}^m \lambda_i^* f_i(x^*) = 0 $，以及$ g(\lambda^*,v^*) = L(x^*,\lambda^*,v^*) $。而因为$ g(\lambda^*,v^*) = min L(x^*,\lambda^*,v^*) $。所以 $ x^* $ 是拉格朗日函数在 $ x $ 方向的驻点，所以有$ \nabla_x L(x^*,\lambda^*,v^*) = 0 $<br>&emsp;&emsp;综上所述，我们得到了KKT条件：<br>&emsp;&emsp;• $ f_i(x^*) ≤ 0, i=1,…,m. $<br>&emsp;&emsp;• $ h_i(x^*) = 0, i=1,…,p. $<br>&emsp;&emsp;• $ \lambda^* ≥ 0, i=1,…,m. $<br>&emsp;&emsp;• $ \sum_{i=1}^m \lambda_i^* f_i(x^*) = 0, i=1,…,m. $<br>&emsp;&emsp;• $ \nabla_x L(x^*,\lambda^*,v^*) = 0 $<br>&emsp;&emsp;KKT条件使用<br>&emsp;&emsp;• 对于凸优化问题,KKT条件是 $ x^*,(\lambda^*,v^*) $ 分别作为原问题和对偶问题的最优解的充分必要条件。<br>&emsp;&emsp;• 对于非凸优化问题，KKT条件仅仅是必要而非充分。</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/Ppaddington.github.io/tags/机器学习/" rel="tag"><i class="fa fa-tag"></i> 机器学习</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/Ppaddington.github.io/2019/09/15/远程访问jupyter-notebook/" rel="next" title="远程访问jupyter notebook">
                <i class="fa fa-chevron-left"></i> 远程访问jupyter notebook
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/Ppaddington.github.io/2019/10/22/哈工大（深圳）推免生复试/" rel="prev" title="哈工大（深圳）推免生复试">
                哈工大（深圳）推免生复试 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/Ppaddington.github.io/images/avatar.png" alt="lalala">
            
              <p class="site-author-name" itemprop="name">lalala</p>
              <p class="site-description motion-element" itemprop="description">翻山而歌</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/Ppaddington.github.io/archives/">
              
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/Ppaddington.github.io/tags/index.html">
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

					<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=27955658&auto=1&height=66"></iframe>
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#数学在机器学习中的应用"><span class="nav-number">1.</span> <span class="nav-text">数学在机器学习中的应用</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#模型建立与选择：对工程问题进行抽象和量化"><span class="nav-number">1.1.</span> <span class="nav-text">模型建立与选择：对工程问题进行抽象和量化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模型训练："><span class="nav-number">1.2.</span> <span class="nav-text">模型训练：</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#微积分"><span class="nav-number">2.</span> <span class="nav-text">微积分</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#微积分核心思想：函数逼近"><span class="nav-number">2.1.</span> <span class="nav-text">微积分核心思想：函数逼近</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#极限"><span class="nav-number">2.2.</span> <span class="nav-text">极限</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#导数"><span class="nav-number">2.3.</span> <span class="nav-text">导数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#从线性逼近到多项式逼近：泰勒级数"><span class="nav-number">2.4.</span> <span class="nav-text">从线性逼近到多项式逼近：泰勒级数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#梯度下降"><span class="nav-number">2.5.</span> <span class="nav-text">梯度下降</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#梯度下降的线性回归"><span class="nav-number">2.6.</span> <span class="nav-text">梯度下降的线性回归</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#多变量梯度下降"><span class="nav-number">2.7.</span> <span class="nav-text">多变量梯度下降</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#概率论"><span class="nav-number">3.</span> <span class="nav-text">概率论</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#极大似然估计"><span class="nav-number">3.1.</span> <span class="nav-text">极大似然估计</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#凸优化"><span class="nav-number">4.</span> <span class="nav-text">凸优化</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#优化问题简介"><span class="nav-number">4.1.</span> <span class="nav-text">优化问题简介</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#凸集合与凸函数"><span class="nav-number">4.2.</span> <span class="nav-text">凸集合与凸函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#凸集合"><span class="nav-number">4.2.0.1.</span> <span class="nav-text">凸集合</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#凸函数"><span class="nav-number">4.2.0.2.</span> <span class="nav-text">凸函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#上境图"><span class="nav-number">4.2.0.3.</span> <span class="nav-text">上境图</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#凸组合"><span class="nav-number">4.2.0.4.</span> <span class="nav-text">凸组合</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#集合的凸包"><span class="nav-number">4.2.0.5.</span> <span class="nav-text">集合的凸包</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#函数的凸闭包"><span class="nav-number">4.2.0.6.</span> <span class="nav-text">函数的凸闭包</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#凸集合的性质"><span class="nav-number">4.2.0.7.</span> <span class="nav-text">凸集合的性质</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#凸函数的性质"><span class="nav-number">4.2.0.8.</span> <span class="nav-text">凸函数的性质</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#凸优化问题"><span class="nav-number">4.3.</span> <span class="nav-text">凸优化问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#优化问题的对偶性"><span class="nav-number">4.4.</span> <span class="nav-text">优化问题的对偶性</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#优化问题"><span class="nav-number">4.4.0.1.</span> <span class="nav-text">优化问题</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#优化问题的对偶问题"><span class="nav-number">4.4.0.2.</span> <span class="nav-text">优化问题的对偶问题</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#Slater-条件"><span class="nav-number">4.4.0.2.0.1.</span> <span class="nav-text">Slater 条件</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#KKT-条件"><span class="nav-number">4.4.0.2.0.2.</span> <span class="nav-text">KKT 条件</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">lalala</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">25k</span>
  
</div>

<!--

  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>




  <span class="post-meta-divider">|</span>




  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>

-->




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/Ppaddington.github.io/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/Ppaddington.github.io/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/Ppaddington.github.io/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/Ppaddington.github.io/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/Ppaddington.github.io/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/Ppaddington.github.io/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/Ppaddington.github.io/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/Ppaddington.github.io/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/Ppaddington.github.io/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/Ppaddington.github.io/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/Ppaddington.github.io/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/Ppaddington.github.io/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/Ppaddington.github.io/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/Ppaddington.github.io/js/src/bootstrap.js?v=5.1.4"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->



  


  




	





  





  












  





  

  

  

  
  

  
  


  

  

<script src="/Ppaddington.github.io/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"jsonPath":"/Ppaddington.github.io/live2dw/assets/wanko.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false,"tagMode":false});</script></body>
</html>
